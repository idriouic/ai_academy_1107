{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d57e9300",
   "metadata": {},
   "source": [
    "# Orchestration Frameworks for LLM Applications\n",
    "\n",
    "This notebook explores orchestration frameworks that simplify the process of designing, composing, and managing large language model (LLM) applications. We'll focus on two popular open-source orchestration frameworks:\n",
    "\n",
    "- **LangChain**\n",
    "- **Semantic Kernel (SK)**\n",
    "\n",
    "Both help developers connect LLMs with tools, memory, APIs, and logic in reusable and modular ways. This notebook includes a brief introduction to orchestration concepts, followed by quickstart examples with each framework.\n",
    "\"\"\"\n",
    "\n",
    "What is an Orchestration Framework?\n",
    "\"\"\"\n",
    "An **orchestration framework** in the context of LLMs enables the structured combination of:\n",
    "- Language models (like OpenAI's GPT-4)\n",
    "- Tools and APIs\n",
    "- Memory and state management\n",
    "- Logic and control flow (e.g., chains, planners, agents)\n",
    "\n",
    "The goal is to build complex AI workflows that:\n",
    "- Maintain modularity and readability\n",
    "- Enable debugging and monitoring\n",
    "- Support integration with real-world systems\n",
    "\n",
    "These frameworks abstract boilerplate code, promote reusability, and facilitate best practices.\n",
    "\n",
    "\n",
    "**Key Differences**:\n",
    "- LangChain is Python-native and community-driven\n",
    "- Semantic Kernel is backed by Microsoft, designed to work with C#, Python, and Java\n",
    "\n",
    "Each has its strengths, and the choice often depends on:\n",
    "- Preferred programming language\n",
    "- Tooling and integration needs\n",
    "- Use case based (Research and prototyping vs scalable production workflows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### When to use Langchain\n",
    "\n",
    "- You want to **experiment fast** and build **interactive AI agents**  \n",
    "- Your application involves **multiple LLMs or data sources**  \n",
    "- You prefer a **rich ecosystem of tools and integrations**\n",
    "\n",
    "---\n",
    "\n",
    "Langchain gives you the **freedom to innovate quickly** — ideal when flexibility and fast iteration are key.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54aa040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft was founded by Bill Gates and Paul Allen. They established the company on April 4, 1975.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "# Instantiate Langchain Chat Model with Azure OpenAI\n",
    "\n",
    "# Langchain wraps the Azure OpenAI client via AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=os.getenv(\"deployment\"),\n",
    "    openai_api_version=os.getenv(\"api_version\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    ")\n",
    "#Define a Simple Chat Prompt and Get Response\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an AI assistant that helps people find information.\"),\n",
    "    HumanMessage(content=\"Who were the founders of Microsoft?\")\n",
    "]\n",
    "\n",
    "response = llm(messages)\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ec538b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Who were the founders of Microsoft?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Microsoft was founded by Bill Gates and Paul Allen. The company was established on April 4, 1975. The two childhood friends from Seattle shared a passion for computers and saw the potential for software development in the burgeoning personal computing industry. Their first major success was developing and selling a BASIC interpreter for the Altair 8800, an early personal computer. This success laid the groundwork for the growth of Microsoft into one of the largest software companies in the world, with its flagship product, the Windows operating system, becoming a dominant force in the industry.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Who were the founders of Microsoft?\n",
      "AI: Microsoft was founded by Bill Gates and Paul Allen. The company was established on April 4, 1975. The two childhood friends from Seattle shared a passion for computers and saw the potential for software development in the burgeoning personal computing industry. Their first major success was developing and selling a BASIC interpreter for the Altair 8800, an early personal computer. This success laid the groundwork for the growth of Microsoft into one of the largest software companies in the world, with its flagship product, the Windows operating system, becoming a dominant force in the industry.\n",
      "Human: When did they start the company?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bill Gates and Paul Allen started Microsoft on April 4, 1975. They began their partnership after seeing an article about the Altair 8800 in Popular Electronics magazine, which inspired them to create a BASIC interpreter for the machine. This project marked the beginning of Microsoft and set the stage for their future innovations in software development. Their vision and collaboration would eventually lead Microsoft to become a key player in the technology and software industry.\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# Initialize memory object\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Create a conversation chain with memory\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# First question\n",
    "print(conversation.predict(input=\"Who were the founders of Microsoft?\"))\n",
    "\n",
    "# Second question — will have context\n",
    "print(conversation.predict(input=\"When did they start the company?\"))\n",
    "# Why this matters: With just a few lines, your LLM becomes context-aware — useful for dialogue agents, customer support, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a070d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the GetFounders tool to find out who founded Google. \n",
      "Action: GetFounders\n",
      "Action Input: Google\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLarry Page and Sergey Brin\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: Google was founded by Larry Page and Sergey Brin.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Google was founded by Larry Page and Sergey Brin.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: Define a custom tool that simulates a function call\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "def get_company_founders(company: str) -> str:\n",
    "    founders = {\n",
    "        \"Microsoft\": \"Bill Gates and Paul Allen\",\n",
    "        \"Google\": \"Larry Page and Sergey Brin\"\n",
    "    }\n",
    "    return founders.get(company, \"Unknown\")\n",
    "\n",
    "# Wrap it as a Langchain tool\n",
    "founder_tool = Tool(\n",
    "    name=\"GetFounders\",\n",
    "    func=get_company_founders,\n",
    "    description=\"Use this to get the founders of a company. Input should be a company name.\"\n",
    ")\n",
    "# Cell 2: Call via Langchain Agent with the tool\n",
    "agent = initialize_agent(\n",
    "    tools=[founder_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "agent.run(\"Who founded Google?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47106c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer the question, I need to find the current weather in Paris.\n",
      "\n",
      "Action: GetWeather\n",
      "Action Input: Paris\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSunny, 25°C\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer. \n",
      "Final Answer: The current weather in Paris is sunny with a temperature of 25°C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The current weather in Paris is sunny with a temperature of 25°C.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Simulate a weather lookup tool\n",
    "from langchain.tools import Tool\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    weather_data = {\n",
    "        \"Paris\": \"Sunny, 25°C\",\n",
    "        \"London\": \"Cloudy, 18°C\",\n",
    "        \"New York\": \"Rainy, 20°C\"\n",
    "    }\n",
    "    return weather_data.get(city, f\"Sorry, no weather data available for {city}.\")\n",
    "\n",
    "weather_tool = Tool(\n",
    "    name=\"GetWeather\",\n",
    "    func=lambda input_text: get_weather(input_text),\n",
    "    description=\"Get the current weather for a city. Input should be a city name.\"\n",
    ")\n",
    "# Cell 2: Use with Langchain Agent\n",
    "agent = initialize_agent(\n",
    "    tools=[weather_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "response = agent.run(\"What is the weather like in Paris?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f63c21",
   "metadata": {},
   "source": [
    "# Semantic Kernel: From Prototypes to Production-Grade AI Workflows 🚀\n",
    "\n",
    "---\n",
    "\n",
    "### What is Semantic Kernel?\n",
    "\n",
    "Semantic Kernel (SK) is an AI orchestration framework designed for **building robust, scalable AI workflows** that go beyond prototyping.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Plugins:** Modular AI components that perform specific tasks or business logic.  \n",
    "- **Planners:** Orchestrators that combine plugins into multi-step, context-aware workflows.  \n",
    "\n",
    "---\n",
    "\n",
    "### Why Semantic Kernel? 🌟\n",
    "\n",
    "| Feature                     | Semantic Kernel                         | Langchain / Prototyping Tools          |\n",
    "|-----------------------------|---------------------------------------|---------------------------------------|\n",
    "| Production Readiness         |  Native RBAC, error handling, logging | Mainly prototyping and experimentation |\n",
    "| Workflow Orchestration       |  Complex, stateful, multi-step       |  Basic chaining or manual orchestration |\n",
    "| Enterprise Integration       |  Built-in support for APIs, identity |  Limited native integration          |\n",
    "| Governance & Compliance      |  Versioning & lifecycle management   |  Requires extra layers                |\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use Semantic Kernel\n",
    "\n",
    "- You need **scalable, secure, and maintainable AI workflows**  \n",
    "- Your project demands **deep integration with existing business systems**  \n",
    "- You want **built-in governance and enterprise-grade controls**\n",
    "\n",
    "---\n",
    "\n",
    "Semantic Kernel bridges the gap between AI experiments and real-world production applications — empowering teams to deliver **reliable, secure, and intelligent automation** at scale.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823686dc",
   "metadata": {},
   "source": [
    "# Semantic Kernel Plugins: The building blocks of intelligent workflows \n",
    "\n",
    "Plugins in Semantic Kernel are **modular AI components** designed to encapsulate specific functionality — whether it's calling an LLM with a custom prompt, integrating with APIs, or executing domain-specific logic.\n",
    "\n",
    "Unlike Langchain’s more free-form chaining of tools, Semantic Kernel plugins are **first-class citizens** with built-in support for:\n",
    "\n",
    "- **Native parameterization and templating**\n",
    "- **Reusable and composable logic**\n",
    "- **Tighter integration with planners and memory**\n",
    "- **Enterprise features like RBAC and versioning**\n",
    "\n",
    "Plugins help SK deliver **scalable, maintainable, and production-ready AI workflows**, allowing teams to build complex systems by composing these modular blocks.\n",
    "\n",
    "---\n",
    "\n",
    "### Simple Plugin Example: Menu Plugin\n",
    "Defines functions to:\n",
    "List daily specials (e.g., soups, salads, drinks)\n",
    "Return prices for requested menu items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22246ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"price\":9.99,\"name\":\"Soup Special: Clam Chowder\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Annotated\n",
    "from pydantic import BaseModel\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatPromptExecutionSettings\n",
    "from semantic_kernel.functions import kernel_function, KernelArguments\n",
    "\n",
    "# Define the plugin with semantic kernel functions\n",
    "class MenuPlugin:\n",
    "    @kernel_function(description=\"Provides a list of specials from the menu.\")\n",
    "    def get_specials(self) -> Annotated[str, \"Returns the specials from the menu.\"]:\n",
    "        return \"\"\"\n",
    "        Special Soup: Clam Chowder\n",
    "        Special Salad: Cobb Salad\n",
    "        Special Drink: Chai Tea\n",
    "        \"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Provides the price of the requested menu item.\")\n",
    "    def get_item_price(\n",
    "        self, menu_item: Annotated[str, \"The name of the menu item.\"]\n",
    "    ) -> Annotated[str, \"Returns the price of the menu item.\"]:\n",
    "        return \"$9.99\"\n",
    "\n",
    "class MenuItem(BaseModel):\n",
    "    price: float\n",
    "    name: str\n",
    "\n",
    "async def main():\n",
    "    # Configure structured outputs format\n",
    "    settings = OpenAIChatPromptExecutionSettings()\n",
    "    settings.response_format = MenuItem\n",
    "\n",
    "    # Create the ChatCompletionAgent with the Azure OpenAI service and the plugin\n",
    "    agent = ChatCompletionAgent(\n",
    "        service=AzureChatCompletion(\n",
    "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            api_version=os.getenv(\"api_version\"),\n",
    "            deployment_name=os.getenv('deployment'),\n",
    "            endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        ),\n",
    "        name=\"SK-Assistant\",\n",
    "        instructions=\"You are a helpful assistant.\",\n",
    "        plugins=[MenuPlugin()],\n",
    "        arguments=KernelArguments(settings),\n",
    "    )\n",
    "\n",
    "    # Ask the agent a question\n",
    "    response = await agent.get_response(\"What is the price of the soup special?\")\n",
    "    print(response.content)\n",
    "\n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
